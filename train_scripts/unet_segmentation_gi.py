# -*- coding: utf-8 -*-
"""unet_segmentation_gi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17bgGZA5nCuTxJkFt540kBL37JFVzDsL0
"""

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D,Dropout,MaxPooling2D,Conv2DTranspose,Input,concatenate,Lambda
from tensorflow.keras.activations import relu,sigmoid
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.losses import BinaryCrossentropy
import os
from skimage.io import imread,imshow
from skimage.transform import resize
import numpy as np
from tqdm import tqdm

IMAGE_LENGTH = 256
IMAGE_WIDTH = 256
IMAGE_CHANNELS = 3
TOTAL_IMAGE = len(os.listdir("/content/drive/MyDrive/Repositories/endoscopy_segmentations/data/images"))
IMAGE_PATH = "/content/drive/MyDrive/Repositories/endoscopy_segmentations/data/images/"
MASK_PATH = "/content/drive/MyDrive/Repositories/endoscopy_segmentations/data/masks/"
X_train=np.zeros((TOTAL_IMAGE,IMAGE_LENGTH,IMAGE_WIDTH,IMAGE_CHANNELS)).astype(np.float32)
Y_train=np.zeros((TOTAL_IMAGE,IMAGE_LENGTH,IMAGE_WIDTH,1)).astype(np.bool)
print((Y_train).shape)
num=0
for file_ in tqdm(os.listdir("/content/drive/MyDrive/Repositories/endoscopy_segmentations/data/images")):
    file_=imread(IMAGE_PATH +  file_)[:,:,:IMAGE_CHANNELS]
    #imshow(file_)
    file_ = resize(file_,(IMAGE_LENGTH,IMAGE_WIDTH),mode="reflect",anti_aliasing=True)
    imshow(file_)
    X_train[num] = file_
    num=num+1
num=0
import matplotlib.pyplot as plt
for file_ in tqdm(os.listdir("/content/drive/MyDrive/Repositories/endoscopy_segmentations/data/masks")):
    file_=imread(MASK_PATH +  file_)
    #imshow(file_)
    file_ = resize(file_,(IMAGE_LENGTH,IMAGE_WIDTH),mode="reflect",anti_aliasing=True)[:,:,:1]
    plt.imshow(np.squeeze(file_))
    Y_train[num] = file_
    num=num+1

def build_model(input_layer, start_neurons):


    conv1 = Conv2D(start_neurons * 1, (3, 3), activation="relu", padding="same")(input_layer)
    conv1 = Conv2D(start_neurons * 1, (3, 3), activation="relu", padding="same")(conv1)
    pool1 = MaxPooling2D((2, 2))(conv1)
    pool1 = Dropout(0.1)(pool1)

    conv2 = Conv2D(start_neurons * 2, (3, 3), activation="relu", padding="same")(pool1)
    conv2 = Conv2D(start_neurons * 2, (3, 3), activation="relu", padding="same")(conv2)
    pool2 = MaxPooling2D((2, 2))(conv2)
    pool2 = Dropout(0.15)(pool2)

    conv3 = Conv2D(start_neurons * 4, (3, 3), activation="relu", padding="same")(pool2)
    conv3 = Conv2D(start_neurons * 4, (3, 3), activation="relu", padding="same")(conv3)
    pool3 = MaxPooling2D((2, 2))(conv3)
    pool3 = Dropout(0.1.5)(pool3)

    conv4 = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(pool3)
    conv4 = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(conv4)
    pool4 = MaxPooling2D((2, 2))(conv4)
    pool4 = Dropout(0.15)(pool4)

    # Middle
    convm = Conv2D(start_neurons * 16, (3, 3), activation="relu", padding="same")(pool4)
    convm = Conv2D(start_neurons * 16, (3, 3), activation="relu", padding="same")(convm)
    
    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding="same")(convm)
    uconv4 = concatenate([deconv4, conv4])
    uconv4 = Dropout(0.15)(uconv4)
    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(uconv4)
    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation="relu", padding="same")(uconv4)

    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding="same")(uconv4)
    uconv3 = concatenate([deconv3, conv3])
    uconv3 = Dropout(0.15)(uconv3)
    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation="relu", padding="same")(uconv3)
    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation="relu", padding="same")(uconv3)

    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding="same")(uconv3)
    uconv2 = concatenate([deconv2, conv2])
    uconv2 = Dropout(0.15)(uconv2)
    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation="relu", padding="same")(uconv2)
    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation="relu", padding="same")(uconv2)

    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding="same")(uconv2)
    uconv1 = concatenate([deconv1, conv1])
    uconv1 = Dropout(0.15)(uconv1)
    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation="relu", padding="same")(uconv1)
    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation="relu", padding="same")(uconv1)
    
    output_layer = Conv2D(1, (1,1), padding="same", activation="sigmoid")(uconv1)
    
    return output_layer

img_size_target = 256
input_layer = Input((img_size_target, img_size_target, 3))
output_layer = build_model(input_layer, 16)

output_layer

model= Model(inputs=input_layer,outputs=output_layer)

model

model.compile(optimizer = tf.keras.optimizers.Adam() ,loss = BinaryCrossentropy(),metrics=tf.keras.metrics.Accuracy())

model.summary()

callbacks=[
    tf.keras.callbacks.TensorBoard(log_dir = "/content/drive/MyDrive/Repositories/endoscopy_segmentations/tensorboard",write_graph=True),
    tf.keras.callbacks.ModelCheckpoint("/content/drive/MyDrive/Repositories/endoscopy_segmentations/models/gi_seg.h5", monitor='val_loss', verbose=1, save_best_only=False, ),
    #tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, verbose=1, restore_best_weights=False)
]

!rm -r /content/drive/MyDrive/Repositories/endoscopy_segmentations/tensorboard
!mkdir /content/drive/MyDrive/Repositories/endoscopy_segmentations/tensorboard
!rm -r /content/drive/MyDrive/Repositories/endoscopy_segmentations/tensorboard/logs
!mkdir /content/drive/MyDrive/Repositories/endoscopy_segmentations/tensorboard/logs
!rm /content/drive/MyDrive/Repositories/endoscopy_segmentations/models/gi_seg.h5

model.fit(
    x=X_train,
    y=Y_train, 
    batch_size=64, 
    epochs=250, 
    verbose='auto', 
    callbacks=callbacks, 
    validation_split=0.1,
    shuffle=True,
    validation_batch_size=64
)

tf.keras.backend.clear_session()

# Load the TensorBoard notebook extension
#%load_ext tensorboard

#%tensorboard --logdir /content/drive/MyDrive/Repositories/endoscopy_segmentations/tensorboard/train

